{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy import stats\n",
    "import utils\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "import model.net as net\n",
    "from dataloader import *\n",
    "from train import train_and_evaluate\n",
    "\n",
    "months = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2002/2002 [02:24<00:00, 13.88it/s]\n"
     ]
    }
   ],
   "source": [
    "data_set = 'London_2013'\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "path = path.replace('\\\\', '/')\n",
    "\n",
    "data = get_data(path, data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 1\n",
    "n_clusters = 2\n",
    "method = 'hierarchical/euclidean'\n",
    "\n",
    "path_cluster = os.path.join(path, 'result', data_set, 'clustering', 'point', method, f'n_clusters_{n_clusters}.csv')\n",
    "clusters = pd.read_csv(path_cluster, header=None)\n",
    "path_data = os.path.join(path, 'data', 'deepar')\n",
    "\n",
    "series = data[:, month-1, :months[month-1]*24]\n",
    "\n",
    "weather = get_weather(path, data_set, month)\n",
    "week = get_dow(data_set, month)\n",
    "day = get_hod(month)\n",
    "\n",
    "num_covariates = 4\n",
    "covariates = np.zeros((num_covariates, len(series[0])))\n",
    "covariates[1] = stats.zscore(weather)\n",
    "covariates[2] = stats.zscore(week)\n",
    "covariates[3] = stats.zscore(day)\n",
    "covariates = covariates.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training and evaluation\n",
      "Epoch 1/20\n",
      "train_loss: 0.810928742090861\n",
      "train_loss: 0.39846479892730713\n",
      "train_loss: 0.26568132638931274\n",
      "train_loss: 0.25202178955078125\n",
      "train_loss: 0.1933418313662211\n",
      "train_loss: 0.27647175391515094\n",
      "train_loss: 0.14044452706972757\n",
      "train_loss: 0.12797550360361734\n",
      "train_loss: 0.18297197421391806\n",
      "train_loss: 0.09055677056312561\n",
      "train_loss: 0.203786830107371\n",
      "train_loss: 0.04773290455341339\n",
      "train_loss: 0.0803909848133723\n",
      "train_loss: 0.0755847046772639\n",
      "train_loss: -0.01631621519724528\n",
      "train_loss: -0.05472126603126526\n",
      "train_loss: 0.0816812664270401\n",
      "train_loss: -0.003837788477540016\n",
      "train_loss: -0.09110777576764424\n",
      "train_loss: 0.008345970263083776\n",
      "train_loss: -0.05964496235052744\n",
      "train_loss: -0.12200747927029927\n",
      "train_loss: -0.11944946646690369\n",
      "train_loss: -0.1175386905670166\n",
      "train_loss: -0.0817738672097524\n",
      "train_loss: -0.07605311771233876\n",
      "train_loss: -0.20074248313903809\n",
      "train_loss: -0.18345165252685547\n",
      "train_loss: -0.1818032662073771\n",
      "train_loss: -0.16640826066335043\n",
      "train_loss: -0.22317558526992798\n",
      "train_loss: -0.2176342010498047\n",
      "train_loss: -0.1219283143679301\n",
      "train_loss: -0.19463616609573364\n",
      "train_loss: -0.21861165761947632\n",
      "train_loss: -0.21958710749944052\n",
      "train_loss: -0.2526193658510844\n",
      "train_loss: -0.2387454112370809\n",
      "train_loss: -0.24935895204544067\n",
      "train_loss: -0.3583020766576131\n",
      "train_loss: -0.3012346426645915\n",
      "train_loss: -0.2417146364847819\n",
      "train_loss: -0.3307353655497233\n",
      "train_loss: -0.4095158576965332\n",
      "train_loss: -0.3451802730560303\n",
      "train_loss: -0.38521889845530194\n",
      "train_loss: -0.38147151470184326\n",
      "train_loss: -0.42597587903340656\n",
      "train_loss: -0.3565831979115804\n",
      "- Full test metrics: ND: 0.712; RMSE: 1.106; test_loss: 0.003\n",
      "Current Best ND is: 0.71158\n",
      "Epoch 2/20\n",
      "train_loss: -0.33590543270111084\n",
      "train_loss: -0.3522530794143677\n",
      "train_loss: -0.41541651884714764\n",
      "train_loss: -0.33535222212473553\n",
      "train_loss: -0.4457435607910156\n",
      "train_loss: -0.4817059834798177\n",
      "train_loss: -0.358426292737325\n",
      "train_loss: -0.3734634717305501\n",
      "train_loss: -0.3541812101999919\n",
      "train_loss: -0.30967336893081665\n",
      "train_loss: -0.381128470102946\n",
      "train_loss: -0.38571202754974365\n",
      "train_loss: -0.3932350476582845\n",
      "train_loss: -0.389315128326416\n",
      "train_loss: -0.20543487866719565\n",
      "train_loss: -0.4528159697850545\n",
      "train_loss: -0.4995137055714925\n",
      "train_loss: -0.43206242720286053\n",
      "train_loss: -0.36377453804016113\n",
      "train_loss: -0.4083554744720459\n",
      "train_loss: -0.349703590075175\n",
      "train_loss: -0.38965753714243573\n",
      "train_loss: -0.40351200103759766\n",
      "train_loss: -0.3759746551513672\n",
      "train_loss: -0.4710143009821574\n",
      "train_loss: -0.39917794863382977\n",
      "train_loss: -0.3778945207595825\n",
      "train_loss: -0.3737297058105469\n",
      "train_loss: -0.34197787443796795\n",
      "train_loss: -0.4798942406972249\n",
      "train_loss: -0.32640822728474933\n",
      "train_loss: -0.4591953754425049\n",
      "train_loss: -0.32434823115666706\n",
      "train_loss: -0.443791667620341\n",
      "train_loss: -0.5234164396921793\n",
      "train_loss: -0.389115850130717\n",
      "train_loss: -0.5036356846491495\n",
      "train_loss: -0.4503522713979085\n",
      "train_loss: -0.44407355785369873\n",
      "train_loss: -0.4764810800552368\n",
      "train_loss: -0.3172461191813151\n",
      "train_loss: -0.4146035512288411\n",
      "train_loss: -0.44579001267751056\n",
      "train_loss: -0.4839440584182739\n",
      "train_loss: -0.5090456008911133\n",
      "train_loss: -0.48619170983632404\n",
      "train_loss: -0.47458593050638836\n",
      "train_loss: -0.5550626516342163\n",
      "train_loss: -0.47670574982961017\n",
      "- Full test metrics: ND: 0.631; RMSE: 1.026; test_loss: -0.124\n",
      "Current Best ND is: 0.63121\n",
      "Epoch 3/20\n",
      "train_loss: -0.5940550168355306\n",
      "train_loss: -0.49202807744344074\n",
      "train_loss: -0.4684066375096639\n",
      "train_loss: -0.4915669759114583\n",
      "train_loss: -0.43882906436920166\n",
      "train_loss: -0.522304892539978\n",
      "train_loss: -0.5466461976369222\n",
      "train_loss: -0.6045357386271158\n",
      "train_loss: -0.530871311823527\n",
      "train_loss: -0.5276244481404623\n",
      "train_loss: -0.44442657629648846\n",
      "train_loss: -0.47468964258829754\n",
      "train_loss: -0.47627023855845135\n",
      "train_loss: -0.5456056197484335\n",
      "train_loss: -0.5331795612970988\n",
      "train_loss: -0.5172501802444458\n",
      "train_loss: -0.4866674741109212\n",
      "train_loss: -0.4495413700739543\n",
      "train_loss: -0.4426190455754598\n",
      "train_loss: -0.5152775446573893\n",
      "train_loss: -0.4810957908630371\n",
      "train_loss: -0.5347372690836588\n",
      "train_loss: -0.5942940711975098\n",
      "train_loss: -0.5101050535837809\n",
      "train_loss: -0.5210538705190023\n",
      "train_loss: -0.4734263817469279\n",
      "train_loss: -0.5184133052825928\n",
      "train_loss: -0.5145738124847412\n",
      "train_loss: -0.4815715154012044\n",
      "train_loss: -0.5639133056004842\n",
      "train_loss: -0.5085694789886475\n",
      "train_loss: -0.5968863566716512\n",
      "train_loss: -0.4740479389826457\n",
      "train_loss: -0.5562530755996704\n",
      "train_loss: -0.5075015624364217\n",
      "train_loss: -0.48616639773050946\n",
      "train_loss: -0.5084904034932455\n",
      "train_loss: -0.49568180243174237\n",
      "train_loss: -0.5000947316487631\n",
      "train_loss: -0.5552212397257487\n",
      "train_loss: -0.48455087343851727\n",
      "train_loss: -0.49200232823689777\n",
      "train_loss: -0.5644059181213379\n",
      "train_loss: -0.6735227902730306\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_clusters):\n",
    "\n",
    "    index = list(clusters[month-1] == i)\n",
    "    sub_series = series[index]\n",
    "    \n",
    "    test_data = sub_series[:, -168*2:].T\n",
    "    train_data = sub_series[:, :-168].T\n",
    "    \n",
    "    data_start = (train_data != 0).argmax(axis=0)\n",
    "    total_time = sub_series.shape[1]\n",
    "    num_series = sub_series.shape[0]\n",
    "    \n",
    "    window_size = 192\n",
    "    stride_size = 24\n",
    "    \n",
    "    # prepare data\n",
    "    cov = covariates.copy()\n",
    "    train_x_input, train_v_input, train_label = prep_data(train_data, cov, data_start, window_size, stride_size, num_covariates, num_series, total_time)\n",
    "    cov = covariates.copy()\n",
    "    test_x_input, test_v_input, test_label = prep_data(test_data, cov, data_start, window_size, stride_size, num_covariates, num_series, total_time, train=False)\n",
    "    \n",
    "    # params\n",
    "    json_path = os.path.join(path, 'forecasting', 'deepar', 'params.json')\n",
    "    params = utils.Params(json_path)\n",
    "    \n",
    "    params.num_class = np.sum(index)\n",
    "    params.relative_metrics = False\n",
    "    params.sampling = False\n",
    "    \n",
    "    # use GPU if available\n",
    "    cuda_exist = torch.cuda.is_available()\n",
    "    # Set random seeds for reproducible experiments if necessary\n",
    "    if cuda_exist:\n",
    "        params.device = torch.device('cuda')\n",
    "        # torch.cuda.manual_seed(240)\n",
    "        model = net.Net(params).cuda()\n",
    "    else:\n",
    "        params.device = torch.device('cpu')\n",
    "        # torch.manual_seed(230)\n",
    "        model = net.Net(params)\n",
    "    \n",
    "    train_set = TrainDataset(train_x_input, train_label)\n",
    "    test_set = TestDataset(test_x_input, test_v_input, test_label)\n",
    "    sampler = WeightedSampler(train_v_input) # Use weighted sampler instead of random sampler\n",
    "    train_loader = DataLoader(train_set, batch_size=params.batch_size, sampler=sampler, num_workers=4)\n",
    "    test_loader = DataLoader(test_set, batch_size=params.predict_batch, sampler=RandomSampler(test_set), num_workers=4)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=params.learning_rate)\n",
    "    loss_fn = net.loss_fn\n",
    "    \n",
    "    restore_file = None\n",
    "    train_and_evaluate(model,\n",
    "                       train_loader,\n",
    "                       test_loader,\n",
    "                       optimizer,\n",
    "                       loss_fn,\n",
    "                       params,\n",
    "                       restore_file)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
