{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy import stats\n",
    "import utils\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "import model.net as net\n",
    "from dataloader import *\n",
    "from train import train_and_evaluate\n",
    "\n",
    "months = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2002/2002 [01:01<00:00, 32.55it/s]\n"
     ]
    }
   ],
   "source": [
    "data_set = 'London_2013'\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "\n",
    "data = get_data(path, data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 1\n",
    "n_clusters = 2\n",
    "method = 'kmeans'\n",
    "\n",
    "path_cluster = os.path.join(path, 'result', data_set, 'clustering', 'point', method, f'n_clusters_{n_clusters}.csv')\n",
    "clusters = pd.read_csv(path_cluster, header=None)\n",
    "\n",
    "series = data[:, month-1, :months[month-1]*24].T.copy()\n",
    "\n",
    "total_time = series.shape[0]\n",
    "num_series = series.shape[1]\n",
    "\n",
    "weather = get_weather(path, data_set, month)\n",
    "week = get_dow(data_set, month)\n",
    "day = get_hod(month)\n",
    "\n",
    "num_covariates = 4\n",
    "covariates = np.zeros((num_covariates, len(series)))\n",
    "covariates[1] = stats.zscore(weather)\n",
    "covariates[2] = stats.zscore(week)\n",
    "covariates[3] = stats.zscore(day)\n",
    "cov_age = stats.zscore(np.arange(total_time))\n",
    "covariates[0] = cov_age\n",
    "covariates = covariates.T.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = series[:-9*24, :].copy()\n",
    "test_data = series[-7*24-168:, :].copy()\n",
    "val_data = series[-9*24-168:-7*24, :].copy()\n",
    "\n",
    "window_size = 192\n",
    "stride_size = 24\n",
    "\n",
    "# prepare data\n",
    "cov = covariates[:-9*24, :].copy()\n",
    "train_x_input, train_v_input, train_label = prep_data(train_data, cov, window_size, stride_size, num_covariates, num_series, clusters[month-1])\n",
    "cov = covariates[-7*24-168:, :].copy()\n",
    "test_x_input, test_v_input, test_label = prep_data(test_data, cov, window_size, stride_size, num_covariates, num_series, clusters[month-1], train=False)\n",
    "cov = covariates[-9*24-168:-7*24, :].copy()\n",
    "val_x_input, val_v_input, val_label = prep_data(val_data, cov, window_size, stride_size, num_covariates, num_series, clusters[month-1], train=False)\n",
    "\n",
    "# params\n",
    "json_path = os.path.join(path, 'forecasting', 'deepar', 'params24.json')\n",
    "params = utils.Params(json_path)\n",
    "\n",
    "params.num_class = n_clusters\n",
    "params.relative_metrics = False\n",
    "params.sampling = False\n",
    "params.one_step = True\n",
    "\n",
    "model_dir = os.path.join(path, 'forecasting', 'deepar')\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "params.model_dir = os.path.join(model_dir, f'n_clusters_{n_clusters}_month_{month}.pth.tar')\n",
    "\n",
    "# use GPU if available\n",
    "cuda_exist = torch.cuda.is_available()\n",
    "\n",
    "# Set random seeds for reproducible experiments if necessary\n",
    "if cuda_exist:\n",
    "    params.device = torch.device('cuda')\n",
    "    # torch.cuda.manual_seed(240)\n",
    "    model = net.Net(params).cuda()\n",
    "else:\n",
    "    params.device = torch.device('cpu')\n",
    "    # torch.manual_seed(230)\n",
    "    model = net.Net(params)\n",
    "\n",
    "# dataset\n",
    "train_set = TrainDataset(train_x_input, train_label)\n",
    "test_set = TestDataset(test_x_input, test_v_input, test_label)\n",
    "val_set = TestDataset(val_x_input, val_v_input, val_label)\n",
    "\n",
    "# sampler\n",
    "train_sampler = WeightedSampler(train_v_input) # Use weighted sampler instead of random sampler\n",
    "\n",
    "# loader\n",
    "train_loader = DataLoader(train_set, batch_size=params.batch_size, sampler=train_sampler, num_workers=4)\n",
    "test_loader = DataLoader(test_set, batch_size=params.predict_batch, sampler=RandomSampler(test_set), num_workers=4)\n",
    "val_loader = DataLoader(val_set, batch_size=params.predict_batch, sampler=RandomSampler(val_set), num_workers=4)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=params.learning_rate)\n",
    "loss_fn = net.loss_fn\n",
    "\n",
    "restore_file = None\n",
    "train_and_evaluate(model,\n",
    "                   train_loader,\n",
    "                   test_loader,\n",
    "                   val_loader,\n",
    "                   optimizer,\n",
    "                   loss_fn,\n",
    "                   params,\n",
    "                   restore_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
