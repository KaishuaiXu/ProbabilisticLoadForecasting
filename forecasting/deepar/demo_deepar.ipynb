{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy import stats\n",
    "import utils\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "import model.net as net\n",
    "from dataloader import *\n",
    "from train import train_and_evaluate\n",
    "\n",
    "months = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [00:29<00:00, 31.53it/s]\n"
     ]
    }
   ],
   "source": [
    "data_set = 'Irish_2010'\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "\n",
    "data = get_data(path, data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 1\n",
    "n_clusters = 2\n",
    "method = 'hierarchical/euclidean'\n",
    "\n",
    "path_cluster = os.path.join(path, 'result', data_set, 'clustering', 'point', method, f'n_clusters_{n_clusters}.csv')\n",
    "clusters = pd.read_csv(path_cluster, header=None)\n",
    "path_data = os.path.join(path, 'data', 'deepar')\n",
    "\n",
    "series = data[:, month-1, :months[month-1]*24]\n",
    "\n",
    "weather = get_weather(path, data_set, month)\n",
    "week = get_dow(data_set, month)\n",
    "day = get_hod(month)\n",
    "\n",
    "num_covariates = 4\n",
    "covariates = np.zeros((num_covariates, len(series[0])))\n",
    "covariates[1] = stats.zscore(weather)\n",
    "covariates[2] = stats.zscore(week)\n",
    "covariates[3] = stats.zscore(day)\n",
    "covariates = covariates.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training\n",
      "Epoch 1/1000\n",
      "train_loss: 1.2481319904327393\n",
      "train_loss: 0.5764206250508627\n",
      "- Full test metrics: ND: 0.596; RMSE: 1.004; test_loss: 0.950\n",
      "Epoch 2/1000\n",
      "train_loss: 0.35280577341715497\n",
      "train_loss: 0.21474790573120117\n",
      "- Full test metrics: ND: 0.538; RMSE: 0.951; test_loss: 0.753\n",
      "Epoch 3/1000\n",
      "train_loss: 0.21759355068206787\n",
      "train_loss: 0.14128215114275613\n",
      "- Full test metrics: ND: 0.533; RMSE: 0.941; test_loss: 0.681\n",
      "Epoch 4/1000\n",
      "train_loss: 0.12473193804423015\n",
      "train_loss: 0.0874929428100586\n",
      "- Full test metrics: ND: 0.536; RMSE: 0.935; test_loss: 0.641\n",
      "Epoch 5/1000\n",
      "train_loss: 0.08409753441810608\n",
      "train_loss: 0.0900423030058543\n",
      "- Full test metrics: ND: 0.519; RMSE: 0.931; test_loss: 0.626\n",
      "Epoch 6/1000\n",
      "train_loss: -0.014974930634101232\n",
      "train_loss: 0.04218562444051107\n",
      "- Full test metrics: ND: 0.521; RMSE: 0.928; test_loss: 0.597\n",
      "Epoch 7/1000\n",
      "train_loss: -0.011313812186320623\n",
      "train_loss: -0.03911385933558146\n",
      "- Full test metrics: ND: 0.518; RMSE: 0.926; test_loss: 0.608\n",
      "Epoch 8/1000\n",
      "train_loss: 0.025811550517876942\n",
      "train_loss: -0.1363996962706248\n",
      "- Full test metrics: ND: 0.519; RMSE: 0.925; test_loss: 0.603\n",
      "Epoch 9/1000\n",
      "train_loss: -0.06902160247166951\n",
      "train_loss: -0.00878500503798326\n",
      "- Full test metrics: ND: 0.518; RMSE: 0.924; test_loss: 0.569\n",
      "Epoch 10/1000\n",
      "train_loss: -0.0901034673055013\n",
      "train_loss: -0.09805954496065776\n",
      "- Full test metrics: ND: 0.520; RMSE: 0.923; test_loss: 0.567\n",
      "Epoch 11/1000\n",
      "train_loss: -0.08789844314257304\n",
      "train_loss: -0.08957045276959737\n",
      "- Full test metrics: ND: 0.509; RMSE: 0.922; test_loss: 0.569\n",
      "Epoch 12/1000\n",
      "train_loss: -0.03326084713141123\n",
      "train_loss: -0.12590118249257407\n",
      "- Full test metrics: ND: 0.512; RMSE: 0.921; test_loss: 0.568\n",
      "Epoch 13/1000\n",
      "train_loss: -0.0999431312084198\n",
      "train_loss: -0.05025083820025126\n",
      "- Full test metrics: ND: 0.507; RMSE: 0.920; test_loss: 0.551\n",
      "Epoch 14/1000\n",
      "train_loss: -0.04964736600716909\n",
      "train_loss: -0.12314098079999287\n",
      "- Full test metrics: ND: 0.511; RMSE: 0.920; test_loss: 0.573\n",
      "Epoch 15/1000\n",
      "train_loss: -0.17191930611928305\n",
      "train_loss: -0.13038999835650125\n",
      "- Full test metrics: ND: 0.509; RMSE: 0.919; test_loss: 0.574\n",
      "Epoch 16/1000\n",
      "train_loss: -0.10574443141619365\n",
      "train_loss: -0.0644679069519043\n",
      "- Full test metrics: ND: 0.509; RMSE: 0.919; test_loss: 0.575\n",
      "Epoch 17/1000\n",
      "train_loss: -0.14774213234583536\n",
      "train_loss: -0.09260093172391255\n",
      "- Full test metrics: ND: 0.514; RMSE: 0.921; test_loss: 0.567\n",
      "Epoch 18/1000\n",
      "train_loss: -0.1470791498819987\n",
      "train_loss: -0.1574801802635193\n",
      "- Full test metrics: ND: 0.508; RMSE: 0.918; test_loss: 0.560\n",
      "Epoch 19/1000\n",
      "train_loss: -0.1360551913579305\n",
      "train_loss: -0.1305868923664093\n",
      "- Full test metrics: ND: 0.502; RMSE: 0.917; test_loss: 0.578\n",
      "Epoch 20/1000\n",
      "train_loss: -0.10957395037015279\n",
      "train_loss: -0.2389267086982727\n",
      "- Full test metrics: ND: 0.502; RMSE: 0.917; test_loss: 0.549\n",
      "Epoch 21/1000\n",
      "train_loss: -0.18073227008183798\n",
      "train_loss: -0.1673478881518046\n",
      "- Full test metrics: ND: 0.503; RMSE: 0.916; test_loss: 0.578\n",
      "Epoch 22/1000\n",
      "train_loss: -0.11680510640144348\n",
      "train_loss: -0.16034454107284546\n",
      "- Full test metrics: ND: 0.503; RMSE: 0.915; test_loss: 0.531\n",
      "Epoch 23/1000\n",
      "train_loss: -0.2156923015912374\n",
      "train_loss: -0.14677782853444418\n",
      "- Full test metrics: ND: 0.501; RMSE: 0.917; test_loss: 0.586\n",
      "Epoch 24/1000\n",
      "train_loss: -0.1091994047164917\n",
      "train_loss: -0.2075217366218567\n",
      "- Full test metrics: ND: 0.507; RMSE: 0.915; test_loss: 0.574\n",
      "Epoch 25/1000\n",
      "train_loss: -0.15658533573150635\n",
      "train_loss: -0.1726547876993815\n",
      "- Full test metrics: ND: 0.501; RMSE: 0.915; test_loss: 0.563\n",
      "Epoch 26/1000\n",
      "train_loss: -0.2680745522181193\n",
      "train_loss: -0.23005982240041098\n",
      "- Full test metrics: ND: 0.501; RMSE: 0.915; test_loss: 0.573\n",
      "Epoch 27/1000\n",
      "train_loss: -0.1826995611190796\n",
      "train_loss: -0.18703981240590414\n",
      "- Full test metrics: ND: 0.497; RMSE: 0.914; test_loss: 0.577\n",
      "Epoch 28/1000\n",
      "train_loss: -0.22753713528315225\n",
      "train_loss: -0.15798606475194296\n",
      "- Full test metrics: ND: 0.498; RMSE: 0.916; test_loss: 0.599\n",
      "Epoch 29/1000\n",
      "train_loss: -0.2619643211364746\n",
      "train_loss: -0.18448980649312338\n",
      "- Full test metrics: ND: 0.496; RMSE: 0.916; test_loss: 0.612\n",
      "Epoch 30/1000\n",
      "train_loss: -0.17961899439493814\n",
      "train_loss: -0.2754300634066264\n",
      "- Full test metrics: ND: 0.492; RMSE: 0.916; test_loss: 0.601\n",
      "Epoch 31/1000\n",
      "train_loss: -0.24630274375279745\n",
      "train_loss: -0.2804418404897054\n",
      "- Full test metrics: ND: 0.498; RMSE: 0.914; test_loss: 0.609\n",
      "Epoch 32/1000\n",
      "train_loss: -0.1912254293759664\n",
      "train_loss: -0.20880407094955444\n",
      "- Full test metrics: ND: 0.496; RMSE: 0.914; test_loss: 0.605\n",
      "Epoch 33/1000\n",
      "train_loss: -0.23246620098749796\n",
      "train_loss: -0.24053778251012167\n",
      "- Full test metrics: ND: 0.497; RMSE: 0.915; test_loss: 0.601\n",
      "Epoch 34/1000\n",
      "train_loss: -0.30226681629816693\n",
      "train_loss: -0.2384515404701233\n",
      "- Full test metrics: ND: 0.497; RMSE: 0.915; test_loss: 0.594\n",
      "Epoch 35/1000\n",
      "train_loss: -0.19163352251052856\n",
      "train_loss: -0.24616614977518717\n",
      "- Full test metrics: ND: 0.495; RMSE: 0.915; test_loss: 0.604\n",
      "Epoch 36/1000\n",
      "train_loss: -0.24372921387354532\n",
      "train_loss: -0.22207093238830566\n",
      "- Full test metrics: ND: 0.495; RMSE: 0.914; test_loss: 0.661\n",
      "Epoch 37/1000\n",
      "train_loss: -0.20697102944056192\n",
      "train_loss: -0.25508280595143634\n",
      "- Full test metrics: ND: 0.496; RMSE: 0.914; test_loss: 0.610\n",
      "Epoch 38/1000\n",
      "train_loss: -0.2816759943962097\n",
      "train_loss: -0.19464262326558432\n",
      "- Full test metrics: ND: 0.497; RMSE: 0.912; test_loss: 0.613\n",
      "Epoch 39/1000\n",
      "train_loss: -0.23960083723068237\n",
      "train_loss: -0.2190328041712443\n",
      "- Full test metrics: ND: 0.496; RMSE: 0.914; test_loss: 0.625\n",
      "Epoch 40/1000\n",
      "train_loss: -0.2869093418121338\n",
      "train_loss: -0.21483665704727173\n",
      "- Full test metrics: ND: 0.495; RMSE: 0.914; test_loss: 0.634\n",
      "Epoch 41/1000\n",
      "train_loss: -0.23419042428334555\n",
      "train_loss: -0.2706506848335266\n",
      "- Full test metrics: ND: 0.494; RMSE: 0.913; test_loss: 0.641\n",
      "Epoch 42/1000\n",
      "train_loss: -0.1894870400428772\n",
      "train_loss: -0.3085266550381978\n",
      "- Full test metrics: ND: 0.497; RMSE: 0.913; test_loss: 0.645\n",
      "Epoch 43/1000\n",
      "train_loss: -0.2821168700853984\n",
      "train_loss: -0.27770890792210895\n",
      "- Full test metrics: ND: 0.501; RMSE: 0.912; test_loss: 0.633\n",
      "Epoch 44/1000\n",
      "train_loss: -0.2747387687365214\n",
      "train_loss: -0.2560931046803792\n",
      "- Full test metrics: ND: 0.499; RMSE: 0.913; test_loss: 0.635\n",
      "Epoch 45/1000\n",
      "train_loss: -0.277207354704539\n",
      "train_loss: -0.28797779480616253\n",
      "- Full test metrics: ND: 0.499; RMSE: 0.913; test_loss: 0.613\n",
      "Epoch 46/1000\n",
      "train_loss: -0.22223536173502603\n",
      "train_loss: -0.31169068813323975\n",
      "- Full test metrics: ND: 0.500; RMSE: 0.913; test_loss: 0.605\n",
      "Epoch 47/1000\n",
      "train_loss: -0.25360820690790814\n",
      "train_loss: -0.28461625178654987\n",
      "- Full test metrics: ND: 0.493; RMSE: 0.914; test_loss: 0.669\n",
      "Epoch 48/1000\n",
      "train_loss: -0.2827269236246745\n",
      "train_loss: -0.2571913202603658\n",
      "- Full test metrics: ND: 0.494; RMSE: 0.913; test_loss: 0.609\n",
      "Epoch 49/1000\n",
      "train_loss: -0.3605115016301473\n",
      "train_loss: -0.2391619880994161\n",
      "- Full test metrics: ND: 0.497; RMSE: 0.912; test_loss: 0.608\n",
      "Epoch 50/1000\n",
      "train_loss: -0.23687599102656046\n",
      "train_loss: -0.20131858189900717\n",
      "- Full test metrics: ND: 0.497; RMSE: 0.912; test_loss: 0.649\n",
      "Epoch 51/1000\n",
      "train_loss: -0.21561654408772787\n",
      "train_loss: -0.3234392801920573\n",
      "- Full test metrics: ND: 0.498; RMSE: 0.913; test_loss: 0.651\n",
      "Epoch 52/1000\n",
      "train_loss: -0.32547295093536377\n",
      "train_loss: -0.29353950421015423\n",
      "- Full test metrics: ND: 0.494; RMSE: 0.913; test_loss: 0.648\n",
      "Epoch 53/1000\n",
      "train_loss: -0.297371784845988\n",
      "train_loss: -0.26401646931966144\n",
      "- Full test metrics: ND: 0.491; RMSE: 0.915; test_loss: 0.615\n",
      "Epoch 54/1000\n",
      "train_loss: -0.24139769872029623\n",
      "train_loss: -0.34036457538604736\n",
      "- Full test metrics: ND: 0.493; RMSE: 0.914; test_loss: 0.696\n",
      "Epoch 55/1000\n",
      "train_loss: -0.28517216444015503\n",
      "train_loss: -0.3822954495747884\n",
      "- Full test metrics: ND: 0.493; RMSE: 0.914; test_loss: 0.672\n",
      "Epoch 56/1000\n",
      "train_loss: -0.23869065443674722\n",
      "train_loss: -0.2415152390797933\n",
      "- Full test metrics: ND: 0.494; RMSE: 0.913; test_loss: 0.672\n",
      "Epoch 57/1000\n",
      "train_loss: -0.25615574916203815\n",
      "train_loss: -0.24452326695124307\n",
      "- Full test metrics: ND: 0.493; RMSE: 0.914; test_loss: 0.682\n",
      "Epoch 58/1000\n",
      "train_loss: -0.32303152481714886\n",
      "train_loss: -0.3691562016805013\n",
      "- Full test metrics: ND: 0.495; RMSE: 0.913; test_loss: 0.681\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: -0.3268589774767558\n",
      "train_loss: -0.20221741994222006\n",
      "- Full test metrics: ND: 0.494; RMSE: 0.914; test_loss: 0.649\n",
      "Epoch 60/1000\n",
      "train_loss: -0.2906075716018677\n",
      "train_loss: -0.3714430332183838\n",
      "- Full test metrics: ND: 0.493; RMSE: 0.914; test_loss: 0.682\n",
      "Epoch 61/1000\n",
      "train_loss: -0.2475046714146932\n",
      "train_loss: -0.2649671832720439\n",
      "- Full test metrics: ND: 0.493; RMSE: 0.913; test_loss: 0.673\n",
      "Epoch 62/1000\n",
      "train_loss: -0.3099132577578227\n",
      "train_loss: -0.2722376187642415\n",
      "- Full test metrics: ND: 0.496; RMSE: 0.913; test_loss: 0.668\n",
      "Epoch 63/1000\n",
      "train_loss: -0.26852885882059735\n",
      "train_loss: -0.21689865986506143\n",
      "- Full test metrics: ND: 0.495; RMSE: 0.914; test_loss: 0.660\n",
      "Epoch 64/1000\n",
      "train_loss: -0.33537499109903973\n",
      "train_loss: -0.334644357363383\n",
      "- Full test metrics: ND: 0.499; RMSE: 0.913; test_loss: 0.677\n",
      "Epoch 65/1000\n",
      "train_loss: -0.3843332926432292\n",
      "train_loss: -0.30988738934199017\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_clusters):\n",
    "\n",
    "    index = list(clusters[month-1] == i)\n",
    "    sub_series = series[index]\n",
    "    \n",
    "    test_data = sub_series[:, -168*2:].T\n",
    "    train_data = sub_series[:, :-168].T\n",
    "    \n",
    "    data_start = (train_data != 0).argmax(axis=0)\n",
    "    total_time = sub_series.shape[1]\n",
    "    num_series = sub_series.shape[0]\n",
    "    \n",
    "    window_size = 192\n",
    "    stride_size = 24\n",
    "    \n",
    "    # prepare data\n",
    "    cov = covariates.copy()\n",
    "    train_x_input, train_v_input, train_label = prep_data(train_data, cov, data_start, window_size, stride_size, num_covariates, num_series, total_time)\n",
    "    cov = covariates.copy()\n",
    "    test_x_input, test_v_input, test_label = prep_data(test_data, cov, data_start, window_size, stride_size, num_covariates, num_series, total_time, train=False)\n",
    "    \n",
    "    # params\n",
    "    json_path = os.path.join(path, 'forecasting', 'deepar', 'params24.json')\n",
    "    params = utils.Params(json_path)\n",
    "    \n",
    "    params.num_class = np.sum(index)\n",
    "    params.relative_metrics = False\n",
    "    params.sampling = False\n",
    "    params.one_step = True\n",
    "    \n",
    "    # use GPU if available\n",
    "    cuda_exist = torch.cuda.is_available()\n",
    "    # Set random seeds for reproducible experiments if necessary\n",
    "    if cuda_exist:\n",
    "        params.device = torch.device('cuda')\n",
    "        # torch.cuda.manual_seed(240)\n",
    "        model = net.Net(params).cuda()\n",
    "    else:\n",
    "        params.device = torch.device('cpu')\n",
    "        # torch.manual_seed(230)\n",
    "        model = net.Net(params)\n",
    "    \n",
    "    train_set = TrainDataset(train_x_input, train_label)\n",
    "    test_set = TestDataset(test_x_input, test_v_input, test_label)\n",
    "    sampler = WeightedSampler(train_v_input) # Use weighted sampler instead of random sampler\n",
    "    train_loader = DataLoader(train_set, batch_size=params.batch_size, sampler=sampler, num_workers=8)\n",
    "    test_loader = DataLoader(test_set, batch_size=params.predict_batch, sampler=RandomSampler(test_set), num_workers=8)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=params.learning_rate)\n",
    "    loss_fn = net.loss_fn\n",
    "    \n",
    "    restore_file = None\n",
    "    train_and_evaluate(model,\n",
    "                       train_loader,\n",
    "                       test_loader,\n",
    "                       optimizer,\n",
    "                       loss_fn,\n",
    "                       params,\n",
    "                       restore_file)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
