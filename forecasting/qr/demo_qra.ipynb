{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.layers import Dense, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from tqdm import trange\n",
    "import tensorflow as tf\n",
    "\n",
    "from dataloader import get_data, get_weather, get_hod, get_dow, get_train_set_qra, get_test_set_qra\n",
    "\n",
    "months = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qloss(y_true, y_pred, q):\n",
    "    tmp1 = (q / 100 - 1) * (y_true - y_pred)\n",
    "    tmp2 = q / 100 * (y_true - y_pred)\n",
    "    return K.mean(K.maximum(tmp1, tmp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [00:27<00:00, 33.00it/s]\n"
     ]
    }
   ],
   "source": [
    "data_set = 'Irish_2010'\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "\n",
    "data = get_data(path, data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 1\n",
    "n_clusters = 2\n",
    "method = 'hierarchical/euclidean'\n",
    "\n",
    "path_cluster = os.path.join(path, 'result', data_set, 'clustering', 'point', method, f'n_clusters_{n_clusters}.csv')\n",
    "clusters = pd.read_csv(path_cluster, header=None)\n",
    "\n",
    "series = data[:, month-1, :months[month-1]*24]\n",
    "weather = get_weather(path, data_set, month)\n",
    "week = get_dow(data_set, month)\n",
    "day = get_hod(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:53<00:00,  3.96s/it]\n",
      "100%|██████████| 99/99 [05:30<00:00,  2.80s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_clusters):\n",
    "\n",
    "    index = list(clusters[month-1] == i)\n",
    "    sub_series = series[index]\n",
    "    sub_series = np.sum(sub_series, axis=0)\n",
    "    \n",
    "    total_series = np.vstack((sub_series, weather, week, day))\n",
    "    \n",
    "    test = total_series[:, -168:]\n",
    "    train = total_series[:, :-168]\n",
    "    \n",
    "    scale = np.zeros(2)\n",
    "    scale[0] = np.max(train[0])\n",
    "    scale[1] = np.min(train[0])\n",
    "    train[0] = (train[0] - scale[1]) / (scale[0] - scale[1])\n",
    "    test[0] = (test[0] - scale[1]) / (scale[0] - scale[1])\n",
    "    \n",
    "    # to get the length of samples\n",
    "    max_lag = 24\n",
    "    max_d = 2\n",
    "    trainX, trainTlag, trainTd, trainY = get_train_set_qra(train, max_lag, max_d)\n",
    "    l = trainY.shape[0]\n",
    "    \n",
    "    num_best = 8\n",
    "    error_train_step1 = np.zeros((24, 2))\n",
    "    pred_train = np.zeros((24, 2, l))\n",
    "    pred_test = np.zeros((24, 2, 168))\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    for lag in trange(1, 25):\n",
    "        for d in range(1, 3):\n",
    "            \n",
    "            trainX, trainTlag, trainTd, trainY = get_train_set_qra(train, lag, d)\n",
    "            testX, testTlag, testTd, testY = get_test_set_qra(train, test, lag, d)\n",
    "\n",
    "            ## QRA step 1\n",
    "            # linear model\n",
    "            inputs = Input((5 + lag*3 + d*3,), name='input')\n",
    "            x = Dense(1, use_bias=True, kernel_initializer='he_normal', bias_initializer='he_normal')(inputs)\n",
    "            model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "            # Train\n",
    "            model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "            hist1 = model.fit(x=np.hstack((trainX, trainTlag, trainTd)), y=trainY, validation_split=0.2, epochs=1000, verbose=0, callbacks=[early_stopping])\n",
    "\n",
    "            # Predict (train)\n",
    "            pred = model.predict(x=np.hstack((trainX, trainTlag, trainTd))[-l:, :])\n",
    "            error_train_step1[lag-1, d-1] = np.sum(np.abs(pred - trainY[-l:, :]))\n",
    "            pred_train[lag-1, d-1] = np.squeeze(pred)\n",
    "            \n",
    "            # Predict (test)\n",
    "            pred = model.predict(x=np.hstack((testX, testTlag, testTd)))\n",
    "            pred_test[lag-1, d-1] = np.squeeze(pred)\n",
    "    \n",
    "    # prepare for step 2\n",
    "    series_train_1 = pred_train[np.argsort(error_train_step1[:,0])[:num_best//2], 0]\n",
    "    series_train_2 = pred_train[np.argsort(error_train_step1[:,1])[:num_best//2], 1]\n",
    "\n",
    "    trainX_ = np.vstack((series_train_1, series_train_2)).T\n",
    "    trainY_ = trainY[-l:, :]\n",
    "    \n",
    "    series_test_1 = pred_test[np.argsort(error_train_step1[:,0])[:num_best//2], 0]\n",
    "    series_test_2 = pred_test[np.argsort(error_train_step1[:,1])[:num_best//2], 1]\n",
    "    \n",
    "    testX_ = np.vstack((series_test_1, series_test_2)).T\n",
    "    testY_ = testY\n",
    "    \n",
    "    ## QRA step 2\n",
    "    # qr model\n",
    "    total_pred = []\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    for q in trange(1, 100):\n",
    "        \n",
    "        input_dim = num_best\n",
    "        model = Sequential([Dense(1, use_bias=True, kernel_initializer='he_normal', bias_initializer='he_normal', input_shape=(input_dim,))])\n",
    "\n",
    "        # Train\n",
    "        model.compile(loss=lambda y_true, y_pred: qloss(y_true, y_pred, q), optimizer='adam')\n",
    "        hist2 = model.fit(x=trainX_, y=trainY_, validation_split=0.2, epochs=1000, verbose=0, callbacks=[early_stopping])\n",
    "\n",
    "        # Predict (train)\n",
    "        pred = model.predict(x=trainX_)\n",
    "        error_train_step2 = qloss(trainY_, pred, q)\n",
    "\n",
    "        # Predict (test)\n",
    "        pred = model.predict(x=testX_)\n",
    "        error_test_step2 = qloss(testY_, pred, q)\n",
    "        total_pred.append(np.squeeze(pred))\n",
    "    \n",
    "    total_pred = np.array(total_pred)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
