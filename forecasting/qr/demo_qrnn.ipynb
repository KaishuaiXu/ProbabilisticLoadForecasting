{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from qrnn import get_model, qloss\n",
    "from dataloader import get_data, get_weather, get_hod, get_dow, get_train_set_qrnn, get_test_set_qrnn\n",
    "\n",
    "months = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [00:46<00:00, 19.20it/s]\n"
     ]
    }
   ],
   "source": [
    "data_set = 'Irish_2010'\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "\n",
    "data = get_data(path, data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 1\n",
    "n_clusters = 2\n",
    "method = 'hierarchical/euclidean'\n",
    "\n",
    "path_cluster = os.path.join(path, 'result', data_set, 'clustering', 'point', method, f'n_clusters_{n_clusters}.csv')\n",
    "clusters = pd.read_csv(path_cluster, header=None)\n",
    "\n",
    "series = data[:, month-1, :months[month-1]*24]\n",
    "weather = get_weather(path, data_set, month)\n",
    "week = get_dow(data_set, month)\n",
    "day = get_hod(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "\n",
    "for i in range(n_clusters):\n",
    "\n",
    "    index = list(clusters[month-1] == i)\n",
    "    sub_series = series[index]\n",
    "    sub_series = np.sum(sub_series, axis=0)\n",
    "    \n",
    "    total_series = np.vstack((sub_series, weather))\n",
    "    \n",
    "    test = total_series[:, -168:]\n",
    "    train = total_series[:, :-168]\n",
    "    \n",
    "    scale = np.zeros(2)\n",
    "    scale[0] = np.max(train[0])\n",
    "    scale[1] = np.min(train[0])\n",
    "    train[0] = (train[0] - scale[1]) / (scale[0] - scale[1])\n",
    "    test[0] = (test[0] - scale[1]) / (scale[0] - scale[1])\n",
    "    \n",
    "    lag = 24\n",
    "    d = 1\n",
    "    \n",
    "    trainX, trainY = get_train_set_qrnn(train, week, day, lag, d)\n",
    "    testX, testY = get_test_set_qrnn(train, test, week, day, lag, d)\n",
    "\n",
    "    # Parameters\n",
    "    input_dim = (lag + d) * 2 + 1 + 7 + 24\n",
    "    num_hidden_layers = 2\n",
    "    num_unit = 10\n",
    "    num_units = [num_unit, num_unit]\n",
    "    act = ['relu', 'relu']\n",
    "\n",
    "    # Get model\n",
    "    model = get_model(input_dim, num_units, act, num_hidden_layers)\n",
    "\n",
    "    # Train\n",
    "    hist = model.fit(x=trainX, y=trainY, validation_split=0.2, epochs=1000, verbose=0, callbacks=[early_stopping])\n",
    "#     hist = model.fit(x=trainX, y=trainY, validation_split=0.2, epochs=700, verbose=0)\n",
    "#     hist = model.fit(x=trainX, y=trainY, epochs=700, verbose=0)\n",
    "    \n",
    "    pred = model.predict(x=trainX)\n",
    "    error_train = qloss(trainY, pred)\n",
    "\n",
    "    # Test\n",
    "    pred = model.predict(x=testX)\n",
    "    error_test = qloss(testY, pred)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('qrnn_train.npy', np.array(error_train))\n",
    "np.save('qrnn_test.npy', np.array(error_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "train = np.load('qrnn_train.npy')\n",
    "test = np.load('qrnn_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train[:, 0])\n",
    "plt.plot(train[:, 1])\n",
    "plt.plot(train[:, 2])\n",
    "plt.legend(['d1', 'd2', 'd3'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test[:, 0])\n",
    "plt.plot(test[:, 1])\n",
    "plt.plot(test[:, 2])\n",
    "plt.legend(['d1', 'd2', 'd3'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
